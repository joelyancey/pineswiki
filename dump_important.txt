
3821.dat0000600 0004000 0002000 00000101636 15004214560 0014253 0ustar00postgrespostgres0000000 0000000 1       1                       \N      2025-04-24 17:27:45.272967+00   2025-04-24 17:27:45.272993+00    f       f       A site migration and upgrade of http://pineswiki.burnham.org/   pineswiki       1       \N      2
2       1                       \N      2025-04-25 17:24:22.685273+00   2025-04-25 17:24:22.685299+00   f       f               Connect 2       \N      2
3       1       How to connect to compute cluster via Windows device            \N      2025-04-25 17:27:58.757074+00   2025-04-25 17:27:58.757102+00   f       f       There are a number of clients available to connect from your Windows PC to the cluster via ssh.\r\n\r\n1. Use a Windows command prompt or Powershell:\r\n\r\n    Type cmd or powershell into the search box on the bottom right of your screen\r\n    A command prompt window will open\r\n    Type ssh -l username pines in the window\r\n    Enter your username and password at the prompts\r\n\r\n2. Use a client program:\r\n\r\nThe command prompt window will work, but you have limited options for fonts and windows sizing. Using a dedicated client, like Putty, will provide a better interface.\r\n\r\nDownload the 'putty.zip' package.\r\n\r\nExtract the putty.exe to your desktop (no installation is necessary)\r\n\r\nDouble-click on the Putty icon to start the program, enter the cluster name ('pines') on the Putty connection screen then click Open: \r\n\r\n<image 1>\r\n\r\nThen your username and password on the Putty login screen to establish a connecton: \r\n\r\n<image 2>        Connect to compute cluster from a Windows device        3\N      2
4       2                       \N      2025-04-25 17:28:22.33046+00    2025-04-25 17:28:22.330488+00   f       f       There are a number of clients available to connect from your Windows PC to the cluster via ssh.\r\n\r\n1. Use a Windows command prompt or Powershell:\r\n\r\n    Type cmd or powershell into the search box on the bottom right of your screen\r\n    A command prompt window will open\r\n    Type ssh -l username pines in the window\r\n    Enter your username and password at the prompts\r\n\r\n2. Use a client program:\r\n\r\nThe command prompt window will work, but you have limited options for fonts and windows sizing. Using a dedicated client, like Putty, will provide a better interface.\r\n\r\nDownload the 'putty.zip' package.\r\n\r\nExtract the putty.exe to your desktop (no installation is necessary)\r\n\r\nDouble-click on the Putty icon to start the program, enter the cluster name ('pines') on the Putty connection screen then click Open: \r\n\r\n[image 1]\r\n\r\nThen your username and password on the Putty login screen to establish a connecton: \r\n\r\n[image 2]        Connect to compute cluster from a Windows device        3       3       2
7       1       How to connect to compute cluster via a macOS device            \N      2025-04-25 17:35:32.893238+00   2025-04-25 17:35:32.893264+00   f       f       Open **Terminal** application and enter:     ssh -l username pines #lowercase 'L'        Connect to compute cluster from a macOS device  6       \N      2
8       2                       \N      2025-04-25 17:36:18.055024+00   2025-04-25 17:36:18.055056+00   f       f       Open **Terminal** application and enter:\r\n    ssh -l username pines #lowercase 'L'     Connect to compute cluster from a macOS device  6       7       2
9       2       Landing page for pineswiki              \N      2025-04-25 17:37:01.746781+00   2025-04-25 17:37:01.746809+00   f       f       A site migration and upgrade of http://pineswiki.burnham.org/\r\n\r\n[TOC]       pineswiki       1       1       2
10      2                       \N      2025-04-25 18:37:54.040132+00   2025-04-25 18:37:54.040161+00   f       f       [article_list depth:2]  Connect 2       2       2
11      3                       \N      2025-04-25 18:38:18.485624+00   2025-04-25 18:38:18.48566+00    f       f       Open **Terminal** application and enter:\r\n    ssh -l username pines #lowercase 'L'     Connect to cluster from macOS device    6       8       2
12      3                       \N      2025-04-25 18:38:51.661673+00   2025-04-25 18:38:51.661701+00   f       f       There are a number of clients available to connect from your Windows PC to the cluster via ssh.\r\n\r\n1. Use a Windows command prompt or Powershell:\r\n\r\n    Type cmd or powershell into the search box on the bottom right of your screen\r\n    A command prompt window will open\r\n    Type ssh -l username pines in the window\r\n    Enter your username and password at the prompts\r\n\r\n2. Use a client program:\r\n\r\nThe command prompt window will work, but you have limited options for fonts and windows sizing. Using a dedicated client, like Putty, will provide a better interface.\r\n\r\nDownload the 'putty.zip' package.\r\n\r\nExtract the putty.exe to your desktop (no installation is necessary)\r\n\r\nDouble-click on the Putty icon to start the program, enter the cluster name ('pines') on the Putty connection screen then click Open: \r\n\r\n[image 1]\r\n\r\nThen your username and password on the Putty login screen to establish a connecton: \r\n\r\n[image 2]        Connect to cluster from Windows device  3       4       2
13      3                       \N      2025-04-25 18:40:12.964378+00   2025-04-25 18:40:12.964405+00   f       f       What is the operating system of the device you will connect to the compute cluster from?\r\n[article_list depth:2]       Connect 2       10      2
14      3                       \N      2025-04-25 18:40:39.78186+00    2025-04-25 18:40:39.781888+00   f       f       A site migration and upgrade of http://pineswiki.burnham.org/\r\n\r\n[article_list]      pineswiki       1       9       2
15      4                       \N      2025-04-25 18:42:33.643534+00   2025-04-25 18:42:33.64356+00    f       f       What is the operating system of the device you will connect to the compute cluster from?\r\n[article_list depth:2]       How to connect  2       13      2
16      5                       \N      2025-04-25 18:42:41.513685+00   2025-04-25 18:42:41.513712+00   f       f       What is the operating system of the device you will connect to the compute cluster from?\r\n[article_list depth:2]       Connect 2       15      2
17      1       Getting started with the compute cluster                \N      2025-04-25 18:45:26.196469+00   2025-04-25 18:45:26.196493+00   f       f       Some preconfigured scripts with sample data are available to demonstrate the SLURM queuing system.\r\n\r\nConnect to the cluster and authenticate with your username and password. (Directions here for PC and Mac)\r\n\r\n**Copy examples folder to your home directory:\r\n**\r\ncp -r /opt/SBP/examples .\r\ncd examples\r\n\r\n**Run a job interactively from the command line:\r\n**\r\nsrun --pty bash\r\n./validate_fastq.sh\r\n\r\n**Or run the script directly from the examples subdirectory:\r\n**\r\nsrun --pty ./validate_fastq.sh\r\n\r\n**Submit as a batch job:**\r\n\r\nsbatch validate_fastq.sh\r\n\r\n*view the contents of validate_fastq.out*\r\n\r\n**Submitting a job to a GPU node:**\r\n\r\nsbatch -p gpu-normal gpu_example.sh    Getting Started 7       \N      2
18      2                       \N      2025-04-25 18:45:51.087953+00   2025-04-25 18:45:51.087981+00   f       f       Some preconfigured scripts with sample data are available to demonstrate the SLURM queuing system.\r\n\r\nConnect to the cluster and authenticate with your username and password. (Directions here for PC and Mac)\r\n\r\n**Copy examples folder to your home directory:**\r\ncp -r /opt/SBP/examples .\r\ncd examples\r\n\r\n**Run a job interactively from the command line:**\r\nsrun --pty bash\r\n./validate_fastq.sh\r\n\r\n**Or run the script directly from the examples subdirectory:**\r\nsrun --pty ./validate_fastq.sh\r\n\r\n**Submit as a batch job:**\r\nsbatch validate_fastq.sh\r\n*view the contents of validate_fastq.out*\r\n\r\n**Submitting a job to a GPU node:**\r\n\r\nsbatch -p gpu-normal gpu_example.sh        Getting Started 7       17      2
19      3                       \N      2025-04-25 18:47:22.217583+00   2025-04-25 18:47:22.217609+00   f       f       Some preconfigured scripts with sample data are available to demonstrate the SLURM queuing system.\r\n\r\nConnect to the cluster and authenticate with your pines username and password. (Directions here for PC and Mac)\r\n\r\n**Copy examples folder to your home directory:**\r\n\r\ncp -r /opt/SBP/examples .\r\ncd examples\r\n\r\n**Run a job interactively from the command line:**\r\n\r\nsrun --pty bash\r\n./validate_fastq.sh\r\n\r\n**Or run the script directly from the examples subdirectory:**\r\n\r\nsrun --pty ./validate_fastq.sh\r\n\r\n**Submit as a batch job:**\r\n\r\nsbatch validate_fastq.sh # now view the contents of validate_fastq.out\r\n\r\n**Submitting a job to a GPU node:**\r\n\r\nsbatch -p gpu-normal gpu_example.sh Getting Started 7       18      2
30      4                       \N      2025-04-25 20:03:02.855848+00   2025-04-25 20:03:02.855875+00   f       f       Open **Terminal** application and enter:\r\n\r\n    ssh -l username pines #lowercase 'L' Connect to cluster from macOS device    6       11      2
20      4                       \N      2025-04-25 18:48:54.940814+00   2025-04-25 18:48:54.94084+00    f       f       Some preconfigured scripts with sample data are available to demonstrate the SLURM queuing system.\r\n\r\nConnect to the cluster and authenticate with your pines username and password. (Directions here for PC and Mac)\r\n\r\n**Copy examples folder to your home directory:**\r\n\r\ncp -r /opt/SBP/examples .\r\ncd examples\r\n\r\n**Run a job interactively from the command line:**\r\n\r\nsrun --pty bash\r\n./validate_fastq.sh\r\n\r\n**Or run the script directly from the examples subdirectory:**\r\n\r\nsrun --pty ./validate_fastq.sh\r\n\r\n**Submit as a batch job:**\r\n\r\nsbatch validate_fastq.sh\r\n\r\n\\# now view the contents of validate_fastq.out\r\n\r\n**Submitting a job to a GPU node:**\r\n\r\nsbatch -p gpu-normal gpu_example.sh        Getting Started 7       19      2
21      1       How to submit jobs using slurm          \N      2025-04-25 18:52:04.970466+00   2025-04-25 18:52:04.970492+00   f       f       **Please avoid running jobs on the headnode (login node)!\r\n**\r\nThe compute and/or GPU nodes should be used for computational work.\r\n\r\nYou can run jobs interactively via the 'srun' command:\r\n\r\nsrun --pty bash\r\n\r\nwill give you a shell on a compute node. Your environment will be intact and the node will act as if you were on the headnode.\r\n\r\nFor jobs run from a script, use the 'sbatch' command:\r\n\r\nsbatch whatever.sh\r\n\r\nfor a standard compute node\r\n\r\nsbatch -p gpu-normal whatever.sh\r\n\r\nfor a GPU node  Running jobs    8       \N      2
22      2                       \N      2025-04-25 19:54:38.923394+00   2025-04-25 19:54:38.923422+00   f       f       **Please avoid running jobs on the headnode (AKA login node)! Only compute and/or GPU nodes are for computational work. If you have just logged into pines, you are on the headnode or login node.**\r\n\r\nA **cluster** consists of many compute nodes. A **compute node** or **"node"** is a single computer in the cluster which can be allocated by you in service of your compute needs. Most of the compute nodes are CPU nodes, but GPU nodes are available also. For many use-cases a CPU node is desirable as it is more computationally flexible. Some applications have specific optimizations that mean they can run much more efficiently on GPU infrastructure.\r\n\r\n**Slurm** is a job scheduler and cluster management system for Linux and Unix-like kernels. It is used by many of the world's supercomputers and computer clusters. Understanding how to use it is a skill that will likely translate to any other high-performance computers that you may someday use. In short, it is how you interact with the cluster.\r\n\r\nThere are two ways of interacting with a compute node: batch mode or interactive mode. In both modes you will have access to the same file shares and your home directory.\r\n\r\n### Batch mode\r\nThis means passive execution, or submitting a script and waiting for the result.\r\n\r\nTo run your script on a standard CPU node, use the **srun** command:\r\n\r\n      sbatch myscript.sh\r\n\r\nOr, on a GPU node:\r\n\r\n      sbatch -p gpu-normal myscript.sh\r\n\r\n### Interactive mode\r\nThis means having a shell on a compute node. Your environment will be intact and the node will act as if you were on the headnode. Use the 'sbatch' command. **Do not compute directly on the headnode.**\r\n\r\nTo launch your interactive session on a standard CPU node, use the **srun** command:\r\n\r\n        srun --pty bash\r\n\r\nOr, on a GPU node:\r\n\r\n       srun --pty --partition=gpu-normal bash       Running jobs in batch or interactively  8       21      2
23      3                       \N      2025-04-25 19:55:05.534055+00   2025-04-25 19:55:05.534081+00   f       f       **Please avoid running jobs on the headnode (AKA login node)! Only compute and/or GPU nodes are for computational work. If you have just logged into pines, you are on the headnode or login node.**\r\n\r\nA **cluster** consists of many compute nodes. A **compute node** or **"node"** is a single computer in the cluster which can be allocated by you in service of your compute needs. Most of the compute nodes are CPU nodes, but GPU nodes are available also. For many use-cases a CPU node is desirable as it is more computationally flexible. Some applications have specific optimizations that mean they can run much more efficiently on GPU infrastructure.\r\n\r\n**Slurm** is a job scheduler and cluster management system for Linux and Unix-like kernels. It is used by many of the world's supercomputers and computer clusters. Understanding how to use it is a skill that will likely translate to any other high-performance computers that you may someday use. In short, it is how you interact with the cluster.\r\n\r\nThere are two ways of interacting with a compute node: batch mode or interactive mode. In both modes you will have access to the same file shares and your home directory.\r\n\r\n### Batch mode\r\nThis means passive execution, or submitting a script and waiting for the result.\r\n\r\nTo run your script on a standard CPU node, use the **srun** command:\r\n\r\n    sbatch myscript.sh\r\n\r\nOr, on a GPU node:\r\n\r\n      sbatch -p gpu-normal myscript.sh\r\n\r\n### Interactive mode\r\nThis means having a shell on a compute node. Your environment will be intact and the node will act as if you were on the headnode. Use the 'sbatch' command. **Do not compute directly on the headnode.**\r\n\r\nTo launch your interactive session on a standard CPU node, use the **srun** command:\r\n\r\n        srun --pty bash\r\n\r\nOr, on a GPU node:\r\n\r\n       srun --pty --partition=gpu-normal bash Running jobs in batch or interactively  8       22      2
24      4                       \N      2025-04-25 19:55:38.737769+00   2025-04-25 19:55:38.737797+00   f       f       **Please avoid running jobs on the headnode (AKA login node)! Only compute and/or GPU nodes are for computational work. If you have just logged into pines, you are on the headnode or login node.**\r\n\r\nA **cluster** consists of many compute nodes. A **compute node** or **"node"** is a single computer in the cluster which can be allocated by you in service of your compute needs. Most of the compute nodes are CPU nodes, but GPU nodes are available also. For many use-cases a CPU node is desirable as it is more computationally flexible. Some applications have specific optimizations that mean they can run much more efficiently on GPU infrastructure.\r\n\r\n**Slurm** is a job scheduler and cluster management system for Linux and Unix-like kernels. It is used by many of the world's supercomputers and computer clusters. Understanding how to use it is a skill that will likely translate to any other high-performance computers that you may someday use. In short, it is how you interact with the cluster.\r\n\r\nThere are two ways of interacting with a compute node: batch mode or interactive mode. In both modes you will have access to the same file shares and your home directory.\r\n\r\n### Batch mode\r\nThis means passive execution, or submitting a script and waiting for the result.\r\n\r\nTo run your script on a standard CPU node, use the **srun** command:\r\n\r\n    sbatch myscript.sh\r\n\r\nOr, on a GPU node:\r\n\r\n    sbatch -p gpu-normal myscript.sh\r\n\r\n### Interactive mode\r\nThis means having a shell on a compute node. Your environment will be intact and the node will act as if you were on the headnode. Use the 'sbatch' command. **Do not compute directly on the headnode.**\r\n\r\nTo launch your interactive session on a standard CPU node, use the **srun** command:\r\n\r\n    srun --pty bash\r\n\r\nOr, on a GPU node:\r\n\r\n    srun --pty --partition=gpu-normal bash  Running jobs in batch or interactively  8       23      2
31      6                       \N      2025-04-25 20:03:36.657116+00   2025-04-25 20:03:36.657143+00   f       f       ###### What operating system will connect to the compute cluster from?\r\n[article_list depth:2] Connect 2       16      2
25      5                       \N      2025-04-25 19:56:03.019564+00   2025-04-25 19:56:03.01959+00    f       f       **Please avoid running jobs on the headnode (AKA login node)! Only compute and/or GPU nodes are for computational work. If you have just logged into pines, you are on the headnode or login node.**\r\n\r\nA **cluster** consists of many compute nodes. A **compute node** or **"node"** is a single computer in the cluster which can be allocated by you in service of your compute needs. Most of the compute nodes are CPU nodes, but GPU nodes are available also. For many use-cases a CPU node is desirable as it is more computationally flexible. Some applications have specific optimizations that mean they can run much more efficiently on GPU infrastructure.\r\n\r\n**Slurm** is a job scheduler and cluster management system for Linux and Unix-like kernels. It is used by many of the world's supercomputers and computer clusters. Understanding how to use it is a skill that will likely translate to any other high-performance computers that you may someday use. In short, it is how you interact with the cluster.\r\n\r\nThere are two ways of interacting with a compute node: **batch mode** or **interactive mode**. In both modes you will have access to the same file shares and your home directory.\r\n\r\n### Batch mode\r\nThis means passive execution, or submitting a script and waiting for the result.\r\n\r\nTo run your script on a standard CPU node, use the **srun** command:\r\n\r\n    sbatch myscript.sh\r\n\r\nOr, on a GPU node:\r\n\r\n    sbatch -p gpu-normal myscript.sh\r\n\r\n### Interactive mode\r\nThis means having a shell on a compute node. Your environment will be intact and the node will act as if you were on the headnode. Use the 'sbatch' command. **Do not compute directly on the headnode.**\r\n\r\nTo launch your interactive session on a standard CPU node, use the **srun** command:\r\n\r\n    srun --pty bash\r\n\r\nOr, on a GPU node:\r\n\r\n    srun --pty --partition=gpu-normal bash  Running jobs in batch or interactively  8       24      2
26      6                       \N      2025-04-25 19:56:20.277377+00   2025-04-25 19:56:20.277404+00   f       f       **Please avoid running jobs on the headnode (AKA login node)!** Only compute and/or GPU nodes are for computational work. If you have just logged into pines, you are on the headnode or login node.\r\n\r\nA **cluster** consists of many compute nodes. A **compute node** or **"node"** is a single computer in the cluster which can be allocated by you in service of your compute needs. Most of the compute nodes are CPU nodes, but GPU nodes are available also. For many use-cases a CPU node is desirable as it is more computationally flexible. Some applications have specific optimizations that mean they can run much more efficiently on GPU infrastructure.\r\n\r\n**Slurm** is a job scheduler and cluster management system for Linux and Unix-like kernels. It is used by many of the world's supercomputers and computer clusters. Understanding how to use it is a skill that will likely translate to any other high-performance computers that you may someday use. In short, it is how you interact with the cluster.\r\n\r\nThere are two ways of interacting with a compute node: **batch mode** or **interactive mode**. In both modes you will have access to the same file shares and your home directory.\r\n\r\n### Batch mode\r\nThis means passive execution, or submitting a script and waiting for the result.\r\n\r\nTo run your script on a standard CPU node, use the **srun** command:\r\n\r\n    sbatch myscript.sh\r\n\r\nOr, on a GPU node:\r\n\r\n    sbatch -p gpu-normal myscript.sh\r\n\r\n### Interactive mode\r\nThis means having a shell on a compute node. Your environment will be intact and the node will act as if you were on the headnode. Use the 'sbatch' command. **Do not compute directly on the headnode.**\r\n\r\nTo launch your interactive session on a standard CPU node, use the **srun** command:\r\n\r\n    srun --pty bash\r\n\r\nOr, on a GPU node:\r\n\r\n    srun --pty --partition=gpu-normal bash  Running jobs in batch or interactively  8       25      2
27      7                       \N      2025-04-25 19:58:09.832856+00   2025-04-25 19:58:09.832882+00   f       f       **Please avoid running jobs on the headnode (AKA login node)!** Only compute and/or GPU nodes are for computational work. If you have just logged into pines, you are on the headnode or login node.\r\n\r\nA **cluster** consists of many compute nodes. A **compute node** or **"node"** is a single computer in the cluster which can be allocated by you in service of your compute needs. Most of the compute nodes are CPU nodes, but GPU nodes are available also. For many use-cases a CPU node is desirable as it is more computationally flexible. Some applications have specific optimizations that mean they can run much more efficiently on GPU infrastructure.\r\n\r\n**Slurm** is a job scheduler and cluster management system for Linux and Unix-like kernels. It is used by many of the world's supercomputers and computer clusters. Understanding how to use it is a skill that will likely translate to any other high-performance computers that you may someday use. In short, it is how you interact with the cluster.\r\n\r\nThere are two ways of interacting with a compute node: **batch mode** or **interactive mode**. In both modes you will have access to the same file shares and your home directory.\r\n\r\n### Batch mode\r\nThis means passive execution, or submitting a script and waiting for the result.\r\n\r\nTo run your script on a standard CPU node, use the **srun** command:\r\n\r\n    sbatch myscript.sh\r\n\r\nOr, on a GPU node:\r\n\r\n    sbatch -p gpu-normal myscript.sh\r\n\r\n### Interactive mode\r\nThis means having a shell on a compute node. Your environment will be intact and the node will act as if you were on the headnode. Use the 'sbatch' command. **Do not compute directly on the headnode.**\r\n\r\nTo launch your interactive session on a standard CPU node, use the **srun** command:\r\n\r\n    srun --pty bash\r\n\r\nOr, on a GPU node:\r\n\r\n    srun --pty --partition=gpu-normal bash  Running jobs    8       26      2
28      4                       \N      2025-04-25 20:00:20.751738+00   2025-04-25 20:00:20.751764+00   f       f       There are a number of clients available to connect from your Windows PC to the cluster via ssh.\r\n\r\n1. Use a Windows command prompt or Powershell:\r\n\r\n    Type cmd or powershell into the search box on the bottom right of your screen\r\n    A command prompt window will open\r\n    Type ssh -l username pines in the window\r\n    Enter your username and password at the prompts\r\n\r\n2. Use a client program:\r\n\r\nThe command prompt window will work, but you have limited options for fonts and windows sizing. Using a dedicated client, like Putty, will provide a better interface.\r\n\r\nDownload the 'putty.zip' package.\r\n\r\nExtract the putty.exe to your desktop (no installation is necessary)\r\n\r\nDouble-click on the Putty icon to start the program, enter the cluster name ('pines') on the Putty connection screen then click Open: \r\n\r\n\r\n[image:1]\r\n\r\n\r\nThen your username and password on the Putty login screen to establish a connecton:  Connect to cluster from Windows device  3       12      2
29      5                       \N      2025-04-25 20:00:46.175625+00   2025-04-25 20:00:46.175652+00   f       f       There are a number of clients available to connect from your Windows PC to the cluster via ssh.\r\n\r\n1. Use a Windows command prompt or Powershell:\r\n\r\n    Type cmd or powershell into the search box on the bottom right of your screen\r\n    A command prompt window will open\r\n    Type ssh -l username pines in the window\r\n    Enter your username and password at the prompts\r\n\r\n2. Use a client program:\r\n\r\nThe command prompt window will work, but you have limited options for fonts and windows sizing. Using a dedicated client, like Putty, will provide a better interface.\r\n\r\nDownload the 'putty.zip' package.\r\n\r\nExtract the putty.exe to your desktop (no installation is necessary)\r\n\r\nDouble-click on the Putty icon to start the program, enter the cluster name ('pines') on the Putty connection screen then click Open: \r\n\r\n\r\n[image:1]\r\n\r\n\r\nThen your username and password on the Putty login screen to establish a connecton:\r\n\r\n\r\n[image:1]     Connect to cluster from Windows device  3       28      2
32      5                       \N      2025-04-25 20:04:55.465721+00   2025-04-25 20:04:55.465747+00   f       f       Some preconfigured scripts with sample data are available to demonstrate the SLURM queuing system.\r\n\r\nConnect to the cluster and authenticate with your pines username and password. (Directions here for PC and Mac)\r\n\r\n**Copy examples folder to your home directory:**\r\n\r\n    cp -r /opt/SBP/examples .\r\n    cd examples\r\n\r\n**Run a job interactively from the command line:**\r\n\r\n    srun --pty bash\r\n    ./validate_fastq.sh\r\n\r\n**Or run the script directly from the examples subdirectory:**\r\n\r\n    srun --pty ./validate_fastq.sh\r\n\r\n**Submit as a batch job:**\r\n\r\n    sbatch validate_fastq.sh\r\n    # now view the contents of validate_fastq.out\r\n\r\n**Submitting a job to a GPU node:**\r\n\r\n    sbatch -p gpu-normal gpu_example.sh      Getting Started 7       20      2
33      1       File storage information                \N      2025-04-25 20:06:54.015745+00   2025-04-25 20:06:54.01577+00    f       f       Each user will get a directory in /home. In addition, each lab will have space in /shares/. This is space is shared with the other members of your lab. We intend to backup /home directories that are < 1 TB in size. Please use the /shares folders for data   File Storage     9       \N      2
34      1       Technical details about hardware                \N      2025-04-25 20:10:59.184856+00   2025-04-25 20:10:59.18488+00    f       f       Compute nodes: (n001 - n012). 2 x 32 core AMD EPYC, 512 GB RAM\r\n\r\nGPU nodes: (gpu001 - gpu006). 2 x 32 core AMD EPYC, 512 GB RAM, 4 NVIDIA RTX 3090\r\n\r\nGPU nodes: (gpu007 - gpu008). 2 x 32 core AMD EPYC, 512 GB RAM, 4 NVIDIA L40S\r\n\r\nGPU nodes: (gpu009). 2 x 32 core AMD EPYC, 512 GB RAM, 1 NVIDIA L40S\r\n\r\nStorage: ~1.7 PB useable BeeGFS filesystem        Technical Details       10      \N      2
35      5                       \N      2025-04-25 20:21:15.413056+00   2025-04-25 20:21:15.413083+00   f       f       Open **Terminal** application and enter:\r\n\r\n    ssh -l username pines #lowercase 'L' from macOS device       6       30      2
36      6                       \N      2025-04-25 20:21:35.060323+00   2025-04-25 20:21:35.060352+00   f       f       There are a number of clients available to connect from your Windows PC to the cluster via ssh.\r\n\r\n1. Use a Windows command prompt or Powershell:\r\n\r\n    Type cmd or powershell into the search box on the bottom right of your screen\r\n    A command prompt window will open\r\n    Type ssh -l username pines in the window\r\n    Enter your username and password at the prompts\r\n\r\n2. Use a client program:\r\n\r\nThe command prompt window will work, but you have limited options for fonts and windows sizing. Using a dedicated client, like Putty, will provide a better interface.\r\n\r\nDownload the 'putty.zip' package.\r\n\r\nExtract the putty.exe to your desktop (no installation is necessary)\r\n\r\nDouble-click on the Putty icon to start the program, enter the cluster name ('pines') on the Putty connection screen then click Open: \r\n\r\n\r\n[image:1]\r\n\r\n\r\nThen your username and password on the Putty login screen to establish a connecton:\r\n\r\n\r\n[image:1]     Connect from Windows device     3       29      2
37      6                       \N      2025-04-25 20:21:49.821395+00   2025-04-25 20:21:49.821424+00   f       f       Open **Terminal** application and enter:\r\n\r\n    ssh -l username pines #lowercase 'L' Connect from macOS device       6       35      2
38      2                       \N      2025-04-25 20:26:36.457803+00   2025-04-25 20:26:36.457829+00   f       f       - Each user gets a directory in /home. \r\n- In addition, each lab gets space in /shares. Use this location for data storage. Data placed here is shared with the other members of your lab.\r\n- We intend to backup /home directories that are < 1 TB in size, but the backups occur with some delay. **Please use the /shares folders for primary data storage.**      File Storage    9       33      2
39      3                       \N      2025-04-25 20:30:34.529044+00   2025-04-25 20:30:34.529071+00   f       f       - Each lab gets space in **/shares**. Data placed here is shared with the other members of your lab. **Please use this for primary data storage.** \r\n- Each user gets a directory in **/home**. We intend to backup /home directories that are < 1 TB in size, but backups are not guaranteed and may occur with some delay.    File Storage    9       38      2
40      4                       \N      2025-04-25 20:33:23.840839+00   2025-04-25 20:33:23.840866+00   f       f       - Each lab gets space in **/shares**. Data placed here is shared with the other members of your lab. **Please use this for primary data storage.** \r\n- Each user gets a directory in **/home**. We intend to backup /home directories that are < 1 TB in size, but backups are not guaranteed and may occur with some delay. - The standard allocation is 20 TB total for your lab group. This includes files in /home and /shares. Additional space can be purchased at a reasonable price.    File Storage     9       39      2
41      5                       \N      2025-04-25 20:34:07.037111+00   2025-04-25 20:34:07.037139+00   f       f       - Each lab gets space in **/shares**. Data placed here is shared with the other members of your lab. **Please use this for primary data storage.** \r\n- Each user gets a directory in **/home**. We intend to backup /home directories that are < 1 TB in size, but backups are not guaranteed and may occur with some delay. \r\n\r\n#####How much storage space does each lab get?\r\nThe standard allocation is 20 TB total for your lab group. This includes files in /home and /shares. Additional space can be purchased at a reasonable price.     File Storage    9       40      2
42      6                       \N      2025-04-25 20:34:25.034687+00   2025-04-25 20:34:25.034714+00   f       f       - Each lab gets space in **/shares**. Data placed here is shared with the other members of your lab. **Please use this for primary data storage.** \r\n- Each user gets a directory in **/home**. We intend to backup /home directories that are < 1 TB in size, but backups are not guaranteed and may occur with some delay. \r\n\r\n##### How much storage space does each lab get?\r\n\r\nThe standard allocation is 20 TB total for your lab group. This includes files in /home and /shares. Additional space can be purchased at a reasonable price.        File
